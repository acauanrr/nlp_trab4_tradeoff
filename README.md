# AnÃ¡lise Quantitativa do Trade-off entre EspecializaÃ§Ã£o e GeneralizaÃ§Ã£o em LLMs

Este projeto implementa um pipeline completo para o **fine-tuning** do modelo `meta-llama/Meta-Llama-3-8B-Instruct` na tarefa de **Text-to-SQL**, utilizando o dataset **Spider**. O objetivo Ã© quantificar o ganho de performance na tarefa especializada e, ao mesmo tempo, medir a regressÃ£o em tarefas de conhecimento geral (MMLU), fornecendo uma anÃ¡lise crÃ­tica do *trade-off* entre **especializaÃ§Ã£o e generalizaÃ§Ã£o** em LLMs.

---

## 1. Estrutura do Projeto

```
/
â”œâ”€â”€ configs/
â”‚   â”œâ”€â”€ lora_config_1.json
â”‚   â””â”€â”€ lora_config_2.json
â”œâ”€â”€ custom_metrics/
â”‚   â””â”€â”€ execution_accuracy.py
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ mmlu_subset/
â”‚   â”‚   â””â”€â”€ mmlu_150_eval.jsonl
â”‚   â””â”€â”€ spider/
â”‚       â”œâ”€â”€ database/
â”‚       â”œâ”€â”€ dev.json
â”‚       â”œâ”€â”€ tables.json
â”‚       â””â”€â”€ train.json
â”œâ”€â”€ results/
â”‚   â””â”€â”€ (outputs dos modelos serÃ£o salvos aqui)
â”œâ”€â”€ scripts/
â”‚   â”œâ”€â”€ preprocess_spider.py
â”‚   â”œâ”€â”€ train_lora.py
â”‚   â”œâ”€â”€ eval_spider.py
â”‚   â””â”€â”€ eval_mmlu.py
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## 2. Setup do Ambiente

### PrÃ©-requisitos:
- Python 3.9+
- NVIDIA GPU com suporte a CUDA (recomendado VRAM â‰¥ 12GB para QLoRA)
- `git` e `git-lfs` instalados

### Passos:

1. Clone o repositÃ³rio:
```bash
git clone [https://github.com/acauanrr/nlp_trab4_tradeoff.git](https://github.com/acauanrr/nlp_trab4_tradeoff.git)
cd nlp_trab4_tradeoff
```

2. Crie e ative um ambiente virtual:
```bash
python -m venv .venv

# Windows
.\.venv\Scriptsctivate

# Linux/macOS
source .venv/bin/activate
```

3. Instale as dependÃªncias:
```bash
pip install -r requirements.txt
```

> **Nota**: Se estiver no Windows e encontrar erros com `bitsandbytes`, consulte soluÃ§Ãµes com versÃµes prÃ©-compiladas. Os scripts jÃ¡ estÃ£o adaptados para contornar o problema, se necessÃ¡rio.

4. Autentique-se no Hugging Face:
```bash
huggingface-cli login
```
> VocÃª precisarÃ¡ de um token com acesso ao modelo Llama-3.

5. Baixe os dados:
- Para o Spider: certifique-se de ter os arquivos `train.json`, `dev.json`, `tables.json` e o diretÃ³rio `database/` em `data/spider/`.
- Para o MMLU: coloque `mmlu_150_eval.jsonl` em `data/mmlu_subset/`.

---

## 3. Pipeline de ExecuÃ§Ã£o End-to-End

### ğŸ”¹ Passo 1: PrÃ©-processar os Dados do Spider
```bash
python scripts/preprocess_spider.py
```
> Gera `train_formatted.jsonl` e `dev_formatted.jsonl` em `data/spider/`.

---

### ğŸ”¹ Passo 2: Avaliar o Modelo Base (Baseline - sem Fine-Tuning)
```bash
python scripts/eval_spider.py --mode baseline --output_file results/baseline_spider_outputs.json --max_samples 20
```
> Mede a `ExecutionAccuracy` em 20 amostras. RelatÃ³rio salvo em `results/baseline_spider_outputs_report.json`.

---

### ğŸ”¹ Passo 3: Treinar os Modelos com LoRA

#### ConfiguraÃ§Ã£o 1:
```bash
python scripts/train_lora.py --config_file configs/lora_config_1.json
```

#### ConfiguraÃ§Ã£o 2:
```bash
python scripts/train_lora.py --config_file configs/lora_config_2.json
```

> Adaptadores sÃ£o salvos em:  
> `results/lora_config_1/final_adapter/`  
> `results/lora_config_2/final_adapter/`

---

### ğŸ”¹ Passo 4: Avaliar os Modelos Fine-Tuned (Text-to-SQL)

#### AvaliaÃ§Ã£o da ConfiguraÃ§Ã£o 1:
```bash
python scripts/eval_spider.py --mode finetuned --lora_adapter_path results/lora_config_1/final_adapter/ --output_file results/finetuned_config1_outputs.json --max_samples 20
```

#### AvaliaÃ§Ã£o da ConfiguraÃ§Ã£o 2:
```bash
python scripts/eval_spider.py --mode finetuned --lora_adapter_path results/lora_config_2/final_adapter/ --output_file results/finetuned_config2_outputs.json --max_samples 20
```

---

### ğŸ”¹ Passo 5: Medir a RegressÃ£o de Capacidade (MMLU)

#### Baseline no MMLU:
```bash
python scripts/eval_mmlu.py
```

#### ConfiguraÃ§Ã£o 1 no MMLU:
```bash
python scripts/eval_mmlu.py --lora_adapter_path results/lora_config_1/final_adapter/
```

#### ConfiguraÃ§Ã£o 2 no MMLU:
```bash
python scripts/eval_mmlu.py --lora_adapter_path results/lora_config_2/final_adapter/
```

---

## ğŸ“Š Objetivo Final

Com os resultados em mÃ£os, vocÃª poderÃ¡ comparar:

- **Ganho de especializaÃ§Ã£o**: Aumento na `ExecutionAccuracy` no dataset Spider.
- **Perda de generalizaÃ§Ã£o**: ReduÃ§Ã£o na performance no subset do MMLU.

Esses dados permitem uma anÃ¡lise crÃ­tica sobre o impacto da especializaÃ§Ã£o em LLMs e o fenÃ´meno do esquecimento catastrÃ³fico.

---

## ğŸ“Œ CrÃ©ditos

Este projeto foi desenvolvido por [Acauan C. Ribeiro](https://github.com/acauanrr) para fins de experimentaÃ§Ã£o acadÃªmica no contexto de *fine-tuning* e avaliaÃ§Ã£o de Large Language Models.

---