# An√°lise Quantitativa do Trade-off entre Especializa√ß√£o e Generaliza√ß√£o em LLMs

Este projeto implementa um pipeline completo para o **fine-tuning** do modelo `meta-llama/Meta-Llama-3-8B-Instruct` na tarefa de **Text-to-SQL**, utilizando o dataset **Spider**. O objetivo √© quantificar o ganho de performance na tarefa especializada e, ao mesmo tempo, medir a regress√£o em tarefas de conhecimento geral (MMLU), fornecendo uma an√°lise cr√≠tica do *trade-off* entre **especializa√ß√£o e generaliza√ß√£o** em LLMs.

---

## 1. Estrutura do Projeto

```
/
‚îú‚îÄ‚îÄ configs/
‚îÇ   ‚îú‚îÄ‚îÄ lora_config_1.json
‚îÇ   ‚îî‚îÄ‚îÄ lora_config_2.json
‚îú‚îÄ‚îÄ custom_metrics/
‚îÇ   ‚îî‚îÄ‚îÄ execution_accuracy.py
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ mmlu_subset/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ mmlu_150_eval.jsonl
‚îÇ   ‚îî‚îÄ‚îÄ spider/
‚îÇ       ‚îú‚îÄ‚îÄ database/
‚îÇ       ‚îú‚îÄ‚îÄ dev.json
‚îÇ       ‚îú‚îÄ‚îÄ tables.json
‚îÇ       ‚îî‚îÄ‚îÄ train.json
‚îú‚îÄ‚îÄ results/
‚îÇ   ‚îî‚îÄ‚îÄ (outputs dos modelos ser√£o salvos aqui)
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ preprocess_spider.py
‚îÇ   ‚îú‚îÄ‚îÄ train_lora.py
‚îÇ   ‚îú‚îÄ‚îÄ eval_spider.py
‚îÇ   ‚îî‚îÄ‚îÄ eval_mmlu.py
‚îú‚îÄ‚îÄ requirements.txt
‚îî‚îÄ‚îÄ README.md
```

---


> üì• **Importante:** Antes de iniciar o pipeline, baixe e descompacte o dataset do projeto (Spider + MMLU subset) dispon√≠vel em:

[https://drive.google.com/file/d/1FC5IgvTHKMSDvGW47HPifwY7RsFt8SS8/view?usp=drive_link](https://drive.google.com/file/d/1FC5IgvTHKMSDvGW47HPifwY7RsFt8SS8/view?usp=drive_link)

Ap√≥s o download, descompacte o conte√∫do diretamente na **raiz do projeto**, de forma que a pasta `/data` esteja presente no mesmo n√≠vel do `README.md`.


## 2. Setup do Ambiente

### Pr√©-requisitos:
- Python 3.9+
- NVIDIA GPU com suporte a CUDA (recomendado VRAM ‚â• 12GB para QLoRA)
- `git` e `git-lfs` instalados

### Passos:

1. Clone o reposit√≥rio:
```bash
git clone <URL_DO_SEU_REPOSITORIO>
cd <NOME_DA_PASTA_DO_PROJETO>
```

2. Crie e ative um ambiente virtual:
```bash
python -m venv .venv

# Windows
.\.venv\Scriptsctivate

# Linux/macOS
source .venv/bin/activate
```

3. Instale as depend√™ncias:
```bash
pip install -r requirements.txt
```

> **Nota**: Se estiver no Windows e encontrar erros com `bitsandbytes`, consulte solu√ß√µes com vers√µes pr√©-compiladas. Os scripts j√° est√£o adaptados para contornar o problema, se necess√°rio.

4. Autentique-se no Hugging Face:
```bash
huggingface-cli login
```
> Voc√™ precisar√° de um token com acesso ao modelo Llama-3.

5. Baixe os dados:
- Para o Spider: certifique-se de ter os arquivos `train.json`, `dev.json`, `tables.json` e o diret√≥rio `database/` em `data/spider/`.
- Para o MMLU: coloque `mmlu_150_eval.jsonl` em `data/mmlu_subset/`.

---

## 3. Pipeline de Execu√ß√£o End-to-End

### üîπ Passo 1: Pr√©-processar os Dados do Spider
```bash
python scripts/preprocess_spider.py
```
> Gera `train_formatted.jsonl` e `dev_formatted.jsonl` em `data/spider/`.

---

### üîπ Passo 2: Avaliar o Modelo Base (Baseline - sem Fine-Tuning)
```bash
python scripts/eval_spider.py --mode baseline --output_file results/baseline_spider_outputs.json --max_samples 20
```
> Mede a `ExecutionAccuracy` em 20 amostras. Relat√≥rio salvo em `results/baseline_spider_outputs_report.json`.

---

### üîπ Passo 3: Treinar os Modelos com LoRA

#### Configura√ß√£o 1:
```bash
python scripts/train_lora.py --config_file configs/lora_config_1.json
```

#### Configura√ß√£o 2:
```bash
python scripts/train_lora.py --config_file configs/lora_config_2.json
```

> Adaptadores s√£o salvos em:  
> `results/lora_config_1/final_adapter/`  
> `results/lora_config_2/final_adapter/`

---

### üîπ Passo 4: Avaliar os Modelos Fine-Tuned (Text-to-SQL)

#### Avalia√ß√£o da Configura√ß√£o 1:
```bash
python scripts/eval_spider.py --mode finetuned --lora_adapter_path results/lora_config_1/final_adapter/ --output_file results/finetuned_config1_outputs.json --max_samples 20
```

#### Avalia√ß√£o da Configura√ß√£o 2:
```bash
python scripts/eval_spider.py --mode finetuned --lora_adapter_path results/lora_config_2/final_adapter/ --output_file results/finetuned_config2_outputs.json --max_samples 20
```

---

### üîπ Passo 5: Medir a Regress√£o de Capacidade (MMLU)

#### Baseline no MMLU:
```bash
python scripts/eval_mmlu.py
```

#### Configura√ß√£o 1 no MMLU:
```bash
python scripts/eval_mmlu.py --lora_adapter_path results/lora_config_1/final_adapter/
```

#### Configura√ß√£o 2 no MMLU:
```bash
python scripts/eval_mmlu.py --lora_adapter_path results/lora_config_2/final_adapter/
```

---

## üìä Objetivo Final

Com os resultados em m√£os, voc√™ poder√° comparar:

- **Ganho de especializa√ß√£o**: Aumento na `ExecutionAccuracy` no dataset Spider.
- **Perda de generaliza√ß√£o**: Redu√ß√£o na performance no subset do MMLU.

Esses dados permitem uma an√°lise cr√≠tica sobre o impacto da especializa√ß√£o em LLMs e o fen√¥meno do esquecimento catastr√≥fico.

---

## üìå Cr√©ditos

Este projeto foi desenvolvido por [Acauan C. Ribeiro](https://github.com/acauanrr) para fins de experimenta√ß√£o acad√™mica no contexto de *fine-tuning* e avalia√ß√£o de Large Language Models.

---